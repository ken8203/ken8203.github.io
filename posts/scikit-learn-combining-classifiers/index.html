<!doctype html><html><head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1,maximum-scale=1"><title>Scikit Learn Combining Classifiers &#183; Hi im jaychung</title><link rel=stylesheet href=https://blog.jaychung.tw/css/slim.css><link rel=stylesheet href=https://blog.jaychung.tw/css/highlight.min.css><link href="https://fonts.googleapis.com/css?family=Source+Sans+Pro:400,700|Source+Code+Pro" rel=stylesheet type=text/css><link rel=apple-touch-icon-precomposed sizes=144x144 href=/apple-touch-icon-144-precomposed.png><link rel="shortcut icon" href=/favicon.ico></head><body><div class=container><div class=header><h1 class=site-title><a href=https://blog.jaychung.tw/>Hi im jaychung</a></h1><p class=site-tagline></p><div class=nav><a class=nav-btn href=#><span class="ci ci-burger"></span></a><ul class=nav-list><li class=spacer>&ac;</li><li><a href=https://github.com/ken8203>Github</a></li><li><a href=https://twitter.com/jaychungtw>Twitter</a></li></ul></div></div><div class=content><div class=post><h2 class=post-title><a href=https://blog.jaychung.tw/posts/scikit-learn-combining-classifiers/>Scikit Learn Combining Classifiers</a></h2><div class=post-content><p>跑 Classification 的傳統方式是決定一個 Classifier 後，透過 feature 的新增或是參數的調整，來提高準確率；而另外一個方法就是集百家之優來改善預測的結果－Essemble。</p><p>今天要介紹的是用 Voting 的方式來決定預測的結果，當然這只是 Essemble 中的其中一種，還有很多其他的方法。</p><p>Scikit-learn 的 Voting 分為 <code>hard</code> 與 <code>soft</code>。</p><p><strong>Hard</strong>
簡單來講就是多數決，例如：</p><p>這樣預測結果就會是 <code>class 1</code>。</p><p><strong>Soft</strong>
這會依照預測出來每個 class 的機率乘上你給的權重（weight）來做定奪，例如：（w1=w2=w3=1）</p><table><thead><tr><th># of classifier</th><th>class 1</th><th>class 2</th><th>class 3</th><th>class 4</th></tr></thead><tbody><tr><td>1</td><td>w1 × 0.2</td><td>w1 × 0.4</td><td>w1 × 0.3</td><td>w1 × 0.1</td></tr><tr><td>2</td><td>w2 × 0.5</td><td>w2 × 0.2</td><td>w2 × 0.1</td><td>w2 × 0.2</td></tr><tr><td>3</td><td>w3 × 0.3</td><td>w3 × 0.1</td><td>w3 × 0.2</td><td>w3 × 0.4</td></tr><tr><td>4</td><td>w4 × 0.1</td><td>w4 × 0.1</td><td>w4 × 0.7</td><td>w4 × 0.1</td></tr><tr><td>weighted average</td><td>0.275</td><td>0.225</td><td>0.325</td><td>0.200</td></tr></tbody></table><p>這樣我們可以看到其中機率最高的是 <code>class 3</code> ， 因此這次分類的結果就是 <code>class 3</code>。</p><h1 id=usage>Usage</h1><div class=highlight><pre style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=color:#f92672>from</span> sklearn <span style=color:#f92672>import</span> cross_validation
<span style=color:#f92672>from</span> sklearn.ensemble <span style=color:#f92672>import</span> RandomForestClassifier, VotingClassifier
<span style=color:#f92672>from</span> sklearn.neighbors <span style=color:#f92672>import</span> KNeighborsClassifier
<span style=color:#f92672>from</span> sklearn.tree <span style=color:#f92672>import</span> DecisionTreeClassifier

knn <span style=color:#f92672>=</span> KNeighborsClassifier(n_neighbors<span style=color:#f92672>=</span><span style=color:#ae81ff>5</span>)
dt <span style=color:#f92672>=</span> DecisionTreeClassifier(random_state<span style=color:#f92672>=</span><span style=color:#ae81ff>1</span>)
lr <span style=color:#f92672>=</span> LogisticRegression(random_state<span style=color:#f92672>=</span><span style=color:#ae81ff>1</span>)

<span style=color:#75715e># hard</span>
eclf <span style=color:#f92672>=</span> VotingClassifier(estimators<span style=color:#f92672>=</span>[(<span style=color:#e6db74>&#39;knn&#39;</span>, knn), (<span style=color:#e6db74>&#39;dt_clf&#39;</span>, dt), (<span style=color:#e6db74>&#39;lr_clf&#39;</span>, lr)], voting<span style=color:#f92672>=</span><span style=color:#e6db74>&#39;hard&#39;</span>)

<span style=color:#75715e># soft</span>
eclf <span style=color:#f92672>=</span> VotingClassifier(estimators<span style=color:#f92672>=</span>[(<span style=color:#e6db74>&#39;knn&#39;</span>, knn), (<span style=color:#e6db74>&#39;dt_clf&#39;</span>, dt), (<span style=color:#e6db74>&#39;lr_clf&#39;</span>, lr)], voting<span style=color:#f92672>=</span><span style=color:#e6db74>&#39;soft&#39;</span>, weights<span style=color:#f92672>=</span>[<span style=color:#ae81ff>1</span>, <span style=color:#ae81ff>2</span>, <span style=color:#ae81ff>3</span>])

scores <span style=color:#f92672>=</span> cross_validation<span style=color:#f92672>.</span>cross_val_score(eclf, recipe_X<span style=color:#f92672>.</span>ingredients, recipe_X<span style=color:#f92672>.</span>cuisine, cv<span style=color:#f92672>=</span><span style=color:#ae81ff>5</span>)
<span style=color:#66d9ef>print</span>(<span style=color:#e6db74>&#34;Accuracy: </span><span style=color:#e6db74>%0.5f</span><span style=color:#e6db74> (+/- </span><span style=color:#e6db74>%0.5f</span><span style=color:#e6db74>)&#34;</span> <span style=color:#f92672>%</span> (scores<span style=color:#f92672>.</span>mean(), scores<span style=color:#f92672>.</span>std() <span style=color:#f92672>*</span> <span style=color:#ae81ff>2</span>))
</code></pre></div><p>更多細節可以參考 <a href=http://scikit-learn.org/stable/modules/ensemble.html>http://scikit-learn.org/stable/modules/ensemble.html</a>。</p></div></div></div><div class=footer><p>Copyright © 2020. Powered by Hugo.</p></div></div><script src=https://blog.jaychung.tw/js/slim.js></script><script>(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)})(window,document,'script','//www.google-analytics.com/analytics.js','ga');ga('create','UA-56558534-1','auto');ga('send','pageview');</script></body></html>